{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tellurium as te\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "import aesara.tensor as at\n",
    "import aesara\n",
    "floatX = aesara.config.floatX\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "import cobra\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import math\n",
    "\n",
    "import cloudpickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')\n",
    "from src import antemll, util\n",
    "import emll\n",
    "from emll.aesara_utils import LeastSquaresSolve\n",
    "os.chdir('notebooks/topologyB/all_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbing enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant ='../../../models/antimony/TopologyB.ant'\n",
    "r = te.loada(ant)\n",
    "r.conservedMoietyAnalysis = True\n",
    "r.steadyState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_levels = [0.5]\n",
    "pt_labels = ['0.5x']\n",
    "\n",
    "data_file05 = '../../../data/interim/generated_data/TopologyB-noReg/TopologyB_0.5.csv'\n",
    "\n",
    "BMCA_obj05 = antemll.antemll(ant, data_file05, cobra_sbml='../../../models/sbml/TopologyB_cobra.xml')\n",
    "\n",
    "prior05 = run_prior_predictive(BMCA_obj05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ADVI(BMCA_obj, lr=5E-3, tgnc=0.7, onm=1):\n",
    "    with pm.Model() as pymc_model:\n",
    "        \n",
    "        # Initialize elasticities\n",
    "        Ex_t = pm.Deterministic('Ex', util.initialize_elasticity(BMCA_obj.Ex.to_numpy(), name='Ex'))\n",
    "        Ey_t = pm.Deterministic('Ey', util.initialize_elasticity(BMCA_obj.Ey.to_numpy(), name='Ey'))\n",
    "        e_obs = pm.Normal('e_obs', mu=1, sigma=10, observed=BMCA_obj.en.T)\n",
    "        chi_obs = pm.Normal('chi_obs', mu=0, sigma=10, observed=BMCA_obj.xn.T)\n",
    "        y_obs = pm.Normal('y_obs', mu=0, sigma=10, observed=BMCA_obj.yn.T)\n",
    "        likelihood = pm.Deterministic('vn', e_obs * (np.ones(BMCA_obj.en.T.shape) + pm.math.dot(Ex_t,chi_obs) + pm.math.dot(Ey_t,y_obs)))\n",
    "        v_hat_obs = pm.Normal('v_hat_obs', mu=likelihood, sigma=0.1, observed=BMCA_obj.vn.squeeze().T)\n",
    "    \n",
    "        N_ITERATIONS = 45000\n",
    "    \n",
    "    with pymc_model:\n",
    "        advi = pm.ADVI()\n",
    "        tracker = pm.callbacks.Tracker(\n",
    "            mean = advi.approx.mean.eval,\n",
    "            std = advi.approx.std.eval\n",
    "        )\n",
    "        approx = advi.fit(\n",
    "            n=N_ITERATIONS, \n",
    "            callbacks = [tracker],\n",
    "            obj_optimizer=pm.adagrad_window(learning_rate=lr), \n",
    "            total_grad_norm_constraint=tgnc,\n",
    "            obj_n_mc=onm)\n",
    "    \n",
    "    with sns.plotting_context('notebook', font_scale=1.2):\n",
    "\n",
    "        fig = plt.figure(figsize=(5,4))\n",
    "        plt.plot(approx.hist + 30, '.', rasterized=True, ms=1)\n",
    "        # plt.ylim([-1E1, 1E3])\n",
    "        plt.xlim([0, N_ITERATIONS])\n",
    "        sns.despine(trim=True, offset=10)\n",
    "\n",
    "        plt.ylabel('-ELBO')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.title('in vitro ADVI convergence')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    with pymc_model:\n",
    "        trace = approx.sample(1000)\n",
    "        ppc_vi = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "    return trace, ppc_vi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_FullRankADVI(BMCA_obj):\n",
    "    with pm.Model() as pymc_model:\n",
    "        \n",
    "        # Initialize elasticities\n",
    "        Ex_t = pm.Deterministic('Ex', util.initialize_elasticity(BMCA_obj.Ex.to_numpy(), name='Ex'))\n",
    "        Ey_t = pm.Deterministic('Ey', util.initialize_elasticity(BMCA_obj.Ey.to_numpy(), name='Ey'))\n",
    "        e_obs = pm.Normal('e_obs', mu=1, sigma=10, observed=BMCA_obj.en.T)\n",
    "        chi_obs = pm.Normal('chi_obs', mu=0, sigma=10, observed=BMCA_obj.xn.T)\n",
    "        y_obs = pm.Normal('y_obs', mu=0, sigma=10, observed=BMCA_obj.yn.T)\n",
    "        likelihood = pm.Deterministic('vn', e_obs * (np.ones(BMCA_obj.en.T.shape) + pm.math.dot(Ex_t,chi_obs) + pm.math.dot(Ey_t,y_obs)))\n",
    "        v_hat_obs = pm.Normal('v_hat_obs', mu=likelihood, sigma=0.1, observed=BMCA_obj.vn.squeeze().T)\n",
    "    \n",
    "        N_ITERATIONS = 45000\n",
    "    \n",
    "    with pymc_model:\n",
    "        advi = pm.FullRankADVI()\n",
    "        tracker = pm.callbacks.Tracker(\n",
    "            mean = advi.approx.mean.eval,\n",
    "            std = advi.approx.std.eval\n",
    "        )\n",
    "        approx = advi.fit(\n",
    "            n=N_ITERATIONS, \n",
    "            callbacks = [tracker],\n",
    "            obj_optimizer=pm.adagrad_window(learning_rate=5E-3), \n",
    "            total_grad_norm_constraint=0.7,\n",
    "            obj_n_mc=1)\n",
    "    \n",
    "    with sns.plotting_context('notebook', font_scale=1.2):\n",
    "\n",
    "        fig = plt.figure(figsize=(5,4))\n",
    "        plt.plot(approx.hist + 30, '.', rasterized=True, ms=1)\n",
    "        # plt.ylim([-1E1, 1E3])\n",
    "        plt.xlim([0, N_ITERATIONS])\n",
    "        sns.despine(trim=True, offset=10)\n",
    "\n",
    "        plt.ylabel('-ELBO')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.title('in vitro ADVI convergence')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    with pymc_model:\n",
    "        trace = approx.sample(1000)\n",
    "        ppc_vi = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "    return trace, ppc_vi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_except(run_ADVI, *params):\n",
    "    try:\n",
    "        return run_ADVI(*params)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a05, aa05 = try_except(run_ADVI, BMCA_obj05)\n",
    "\n",
    "b05, bb05 = try_except(run_ADVI, BMCA_obj05, 5E-3, 0.2)\n",
    "c05, cc05 = try_except(run_ADVI, BMCA_obj05, 0.05, 1)\n",
    "d05, dd05 = try_except(run_ADVI, BMCA_obj05, 0.5, 10)\n",
    "e05, ee05 = try_except(run_ADVI, BMCA_obj05, 5E-3, 1)\n",
    "f05, ff05 = try_except(run_ADVI, BMCA_obj05, 0.05, 10)\n",
    "g05, gg05 = try_except(run_ADVI, BMCA_obj05, 0.5, 0.2)\n",
    "h05, hh05 = try_except(run_ADVI, BMCA_obj05, 5E-3, 10)\n",
    "i05, ii05 = try_except(run_ADVI, BMCA_obj05, 0.05, 0.2)\n",
    "j05, jj05 = try_except(run_ADVI, BMCA_obj05, 0.5, 1)\n",
    "\n",
    "\n",
    "k05, kk05 = try_except(run_FullRankADVI, BMCA_obj05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_var=[a05, b05, c05, d05, e05, f05, g05, h05, i05, j05, k05]\n",
    "single_var_names=[\"a05\", \"b05\", \"c05\", \"d05\", \"e05\", \"f05\", \"g05\", \"h05\", \"i05\", \"j05\", \"k05\"]\n",
    "double_var=[aa05, bb05, cc05, dd05, ee05, ff05, gg05, hh05, ii05, jj05, kk05]\n",
    "double_var_names=[\"aa05\", \"bb05\", \"cc05\", \"dd05\", \"ee05\", \"ff05\", \"gg05\", \"hh05\", \"ii05\", \"jj05\", \"kk05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = {}\n",
    "for i, tr in enumerate(single_var):\n",
    "    try: \n",
    "        jar[single_var_names[i]]=tr\n",
    "        jar[double_var_names[i]]=double_var[i]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving trace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"topologyB-noReg-hptuning05.pgz\", \"wb\") as f:\n",
    "            cloudpickle.dump(\n",
    "                jar,\n",
    "                f,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklefolder = ''\n",
    "with gzip.open(picklefolder + 'topologyB-noReg-hptuning05.pgz', \"rb\") as f:\n",
    "    traces = cloudpickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_var=[a05, b05, c05, d05, e05, f05, g05, h05, i05, j05, k05]\n",
    "single_var_names=[\"a05\", \"b05\", \"c05\", \"d05\", \"e05\", \"f05\", \"g05\", \"h05\", \"i05\", \"j05\", \"k05\"]\n",
    "double_var=[aa05, bb05, cc05, dd05, ee05, ff05, gg05, hh05, ii05, jj05, kk05]\n",
    "double_var_names=[\"aa05\", \"bb05\", \"cc05\", \"dd05\", \"ee05\", \"ff05\", \"gg05\", \"hh05\", \"ii05\", \"jj05\", \"kk05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a05 = traces['a05']\n",
    "aa05 = traces['aa05']\n",
    "b05 = traces['b05']\n",
    "bb05 = traces['bb05']\n",
    "c05 = traces['c05']\n",
    "cc05 = traces['cc05']\n",
    "d05 = traces['d05']\n",
    "dd05 = traces['dd05']\n",
    "e05 = traces['e05']\n",
    "ee05 = traces['ee05']\n",
    "f05 = traces['f05']\n",
    "ff05 = traces['ff05']\n",
    "g05 = traces['g05']\n",
    "gg05 = traces['gg05']\n",
    "h05 = traces['h05']\n",
    "hh05 = traces['hh05']\n",
    "i05 = traces['i05']\n",
    "ii05 = traces['ii05']\n",
    "j05 = traces['j05']\n",
    "jj05 = traces['jj05']\n",
    "k05 = traces['k05']\n",
    "kk05 = traces['kk05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ppc_aa05 = az.summary(aa05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_bb05 = az.summary(bb05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_cc05 = az.summary(cc05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_dd05 = az.summary(dd05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_ee05 = az.summary(ee05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_ff05 = az.summary(ff05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_gg05 = az.summary(gg05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_hh05 = az.summary(hh05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_ii05 = az.summary(ii05['posterior_predictive']['v_hat_obs'])['mean']\n",
    "v_ppc_jj05 = az.summary(jj05['posterior_predictive']['v_hat_obs'])['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ppc_aa05 = az.summary(aa05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_bb05 = az.summary(bb05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_cc05 = az.summary(cc05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_dd05 = az.summary(dd05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_ee05 = az.summary(ee05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_ff05 = az.summary(ff05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_gg05 = az.summary(gg05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_hh05 = az.summary(hh05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_ii05 = az.summary(ii05['posterior_predictive']['chi_obs'])['mean']\n",
    "x_ppc_jj05 = az.summary(jj05['posterior_predictive']['chi_obs'])['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ppc_aa05 = az.summary(aa05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_bb05 = az.summary(bb05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_cc05 = az.summary(cc05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_dd05 = az.summary(dd05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_ee05 = az.summary(ee05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_ff05 = az.summary(ff05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_gg05 = az.summary(gg05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_hh05 = az.summary(hh05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_ii05 = az.summary(ii05['posterior_predictive']['e_obs'])['mean']\n",
    "e_ppc_jj05 = az.summary(jj05['posterior_predictive']['e_obs'])['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ppcs = [v_ppc_aa05, v_ppc_bb05, v_ppc_cc05, v_ppc_dd05, v_ppc_ee05, v_ppc_ff05, v_ppc_gg05, v_ppc_hh05, v_ppc_ii05, v_ppc_jj05]\n",
    "x_ppcs = [x_ppc_aa05, x_ppc_bb05, x_ppc_cc05, x_ppc_dd05, x_ppc_ee05, x_ppc_ff05, x_ppc_gg05, x_ppc_hh05, x_ppc_ii05, x_ppc_jj05]\n",
    "e_ppcs = [e_ppc_aa05, e_ppc_bb05, e_ppc_cc05, e_ppc_dd05, e_ppc_ee05, e_ppc_ff05, e_ppc_gg05, e_ppc_hh05, e_ppc_ii05, e_ppc_jj05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Known flux and metabolite concentrations check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two subplots and unpack the output array immediately\n",
    "f, ax = plt.subplots(10, 3, figsize=(8,16))\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # ax[i,0].set_aspect('equal', 'datalim')\n",
    "    ax[i,0].scatter(BMCA_obj05.vn.values, v_ppcs[i].values.reshape((19,-1)))\n",
    "    ax[i,0].axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "    # ax[i,0].set_title('v_obs, ground truth vs. posterior predictive')\n",
    "    ax[i,0].set_xlabel('ground truth values')\n",
    "    # ax[i,0].set_ylabel('predicted values')\n",
    "    ax[i,0].grid()\n",
    "\n",
    "    # ax[i,1].set_aspect('equal', 'datalim')\n",
    "    ax[i,1].scatter(BMCA_obj05.xn.values, x_ppcs[i].values.reshape((13,-1)))\n",
    "    ax[i,1].axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "    # ax[i,1].set_title('chi_obs, ground truth vs. posterior predictive')\n",
    "    ax[i,1].set_xlabel('ground truth values')\n",
    "    ax[i,1].grid()\n",
    "\n",
    "    # ax[i,2].set_aspect('equal', 'datalim')\n",
    "    ax[i,2].scatter(BMCA_obj05.en.values, e_ppcs[i].values.reshape((19,-1)))\n",
    "    ax[i,2].axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "    # ax[i,2].set_title('e_obs, ground truth vs. posterior predictive')\n",
    "    ax[i,2].set_xlabel('ground truth values')\n",
    "    ax[i,2].grid()\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "f.suptitle('BMCA on Topology B, 0.5x pt, allData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elasticity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex_a = util.get_az_summary(a05)\n",
    "Ex_b = util.get_az_summary(b05)\n",
    "Ex_c = util.get_az_summary(c05)\n",
    "Ex_d = util.get_az_summary(d05)\n",
    "Ex_e = util.get_az_summary(e05)\n",
    "Ex_f = util.get_az_summary(f05)\n",
    "Ex_g = util.get_az_summary(g05)\n",
    "Ex_h = util.get_az_summary(h05)\n",
    "Ex_i = util.get_az_summary(i05)\n",
    "Ex_j = util.get_az_summary(j05)\n",
    "Ex_k = util.get_az_summary(k05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_Ex05_advi = az.summary(prior05['prior']['Ex'])['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_labels= ['0.5x-pr'] + single_var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticity_values = np.column_stack([r.getScaledElasticityMatrix().flatten(),\n",
    "                                prior_Ex05_advi, Ex_a,Ex_b, Ex_c, Ex_d, Ex_e, Ex_f, Ex_g, Ex_h, Ex_i, Ex_j, Ex_k])\n",
    "\n",
    "elasticities_df = pd.DataFrame(elasticity_values, columns=['gt']+pt_labels,\n",
    "                               index=[i + '_' + ii for i in r.getReactionIds() for ii in r.getFloatingSpeciesIds()])\n",
    "# elasticities_df.to_csv('topologyB_allData_elasticities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_slopes = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[0],3) for i in pt_labels]\n",
    "e_intercepts = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[1],3) for i in pt_labels]\n",
    "e_r2s = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[2],3) for i in pt_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elasticities, comparison of prior and post \n",
    "#plt.ylim(-10,10)\n",
    "#plt.xlim(-10,10)\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "for label in pt_labels: \n",
    "    plt.scatter(elasticities_df['gt'], elasticities_df[label], alpha=0.4, label=label, zorder=10)\n",
    "\n",
    "\n",
    "plt.axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "plt.grid(True, which='both', axis='both', zorder=0)\n",
    "plt.xlabel('ground truth elasticity values', size=14)\n",
    "plt.ylabel('predicted elasticity values, $\\it{r}$', size=14)\n",
    "# plt.title('Parity plot of elasticity values for various \\nenzyme perturbation strengthsâ€”CRISPRi', size=20)\n",
    "plt.title('allData ', size=20)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "\n",
    "left_adjust = 20\n",
    "line_spacing = 0.8\n",
    "slope_start = 7.5\n",
    "r2_start = -3# slope_start-(7*line_spacing)\n",
    "\n",
    "plt.text(left_adjust, slope_start, \"slopes\")\n",
    "for i, label in enumerate(pt_labels):\n",
    "    plt.text(left_adjust, (slope_start-line_spacing)-(i*line_spacing), f'{label}: {e_slopes[i]}')\n",
    "\n",
    "plt.text(left_adjust, r2_start, 'R-squared')\n",
    "for i, label in enumerate(pt_labels):\n",
    "    plt.text(left_adjust, (r2_start-line_spacing)-(i*line_spacing), f'{label}: {e_r2s[i]}')\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "for i in range(4):\n",
    "    plt.axline((0, e_intercepts[i]), slope=e_slopes[i], linestyle='--', alpha=0.6, color=colors[i], zorder=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out MAE for each perturbation strength\n",
    "MAE = abs(elasticities_df.sub(elasticities_df['gt'], axis=0)).sum()/len(elasticities_df['gt'])\n",
    "MAE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "MAE.to_csv('../../../data/results/MAE/topologyB-noReg-hptuning05_MAE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating FCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtFCC = pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), index=r.getReactionIds(), columns=r.getReactionIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex05_prior = util.get_az_summary(prior05['prior']['Ex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorFCC05 = util.estimate_CCs(BMCA_obj05, Ex05_prior.reshape((19,-1)))\n",
    "\n",
    "postFCC_a05 = util.estimate_CCs(BMCA_obj05, Ex_a.reshape((19,-1)))\n",
    "postFCC_b05 = util.estimate_CCs(BMCA_obj05, Ex_b.reshape((19,-1)))\n",
    "postFCC_c05 = util.estimate_CCs(BMCA_obj05, Ex_c.reshape((19,-1)))\n",
    "postFCC_d05 = util.estimate_CCs(BMCA_obj05, Ex_d.reshape((19,-1)))\n",
    "postFCC_e05 = util.estimate_CCs(BMCA_obj05, Ex_e.reshape((19,-1)))\n",
    "postFCC_f05 = util.estimate_CCs(BMCA_obj05, Ex_f.reshape((19,-1)))\n",
    "postFCC_g05 = util.estimate_CCs(BMCA_obj05, Ex_g.reshape((19,-1)))\n",
    "postFCC_h05 = util.estimate_CCs(BMCA_obj05, Ex_h.reshape((19,-1)))\n",
    "postFCC_i05 = util.estimate_CCs(BMCA_obj05, Ex_i.reshape((19,-1)))\n",
    "postFCC_j05 = util.estimate_CCs(BMCA_obj05, Ex_j.reshape((19,-1)))\n",
    "postFCC_k05 = util.estimate_CCs(BMCA_obj05, Ex_k.reshape((19,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_FCCs = [priorFCC05]\n",
    "post_FCCs = [postFCC_a05, postFCC_b05, postFCC_c05, postFCC_d05, postFCC_e05, postFCC_f05, postFCC_g05, postFCC_h05, postFCC_i05, postFCC_j05, postFCC_k05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_priorFCCs = pd.concat([util.append_FCC_df(prior_FCCs[i], pt_labels[i]) for i in range(len(prior_FCCs), r)])\n",
    "prd_postFCCs = pd.concat([util.append_FCC_df(post_FCCs[i], pt_labels[i]) for i in range(len(post_FCCs), r)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating FCC ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtFCC=pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), columns=r.getReactionIds(), index=r.getReactionIds()).abs()\n",
    "m1 = gtFCC.index.values[:, None] == gtFCC.columns.values\n",
    "gtFCC = pd.DataFrame(np.select([m1], [float('Nan')], gtFCC), columns=gtFCC.columns, index=gtFCC.index)\n",
    "gtFCC_rankings= gtFCC.rank(axis=1, ascending=False, na_option='keep')\n",
    "\n",
    "a = gtFCC_rankings.loc['v19']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via Spearman rank coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coefficients = []\n",
    "p_values = []\n",
    "confidence_intervals = []\n",
    "b_list = []\n",
    "for FCC in prior_FCCs + post_FCCs:\n",
    "    b = util.calculate_FCC_med_rankings(FCC, reaction='v19')\n",
    "    b_list.append(b)\n",
    "    spearman_r, p_value, lower_ci, upper_ci = util.bootstrap_spearman(a.dropna(), b.dropna())\n",
    "    spearman_coefficients.append(spearman_r)\n",
    "    p_values.append(p_value)\n",
    "    confidence_intervals.append((lower_ci, upper_ci))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_df = pd.DataFrame(spearman_coefficients, columns=['r'], index=pt_labels)\n",
    "spearman_df['p-value'] = p_values\n",
    "spearman_df['lower'] = [i[0] for i in confidence_intervals]\n",
    "spearman_df['upper'] = [i[1] for i in confidence_intervals]\n",
    "spearman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spearman_df.to_csv('../../../data/results/spearman_coefficients/topologyB-noReg-hptuning05_spr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(pt_labels, [i for i in spearman_coefficients], alpha=0.5, color='r')\n",
    "plt.grid()\n",
    "\n",
    "for i, txt in enumerate(spearman_df['r']):\n",
    "    plt.vlines(pt_labels[i], spearman_df['lower'][i], spearman_df['upper'][i], color='k')\n",
    "\n",
    "plt.title(\"Spearman rank correlation coefficients by perturbation strength\")\n",
    "plt.xlabel('perturbation level')\n",
    "plt.ylabel('Spearman $\\it{r}$')\n",
    "plt.ylim((0, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating top 10 rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_list = []\n",
    "for FCC in prior_FCCs + post_FCCs:\n",
    "    b = util.calculate_FCC_med_rankings(FCC, reaction='v19')\n",
    "    b_list.append(b)\n",
    "\n",
    "ranked_b_list = [b.sort_values().reset_index().set_index('v19') for b in b_list]\n",
    "q = pd.concat(ranked_b_list, axis=1)\n",
    "q['gt'] = a.sort_values().reset_index().set_index('v19')\n",
    "q.columns = pt_labels + ['gt']\n",
    "q = q[['gt'] + pt_labels]\n",
    "q.head(15) ## top 15 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.to_csv('../../../data/results/rankings/topologyB-noReg-hptuning05_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.read_csv('../../../data/results/rankings/topologyB-noReg-hptuning05_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topTen_df = rank_df[rank_df['v19'].isin([1,2,3,4,5,6,7,8,9,10])]\n",
    "\n",
    "gt_t10_set = set(list(topTen_df['gt']))\n",
    "\n",
    "t10_sets = []\n",
    "for pt in pt_labels: \n",
    "    t10_sets.append(set(list(topTen_df[pt])))\n",
    "\n",
    "t10_scores=[]\n",
    "for i in t10_sets: \n",
    "    t10_scores.append(len(set.intersection(gt_t10_set, i)))\n",
    "\n",
    "t10_results = pd.DataFrame((np.array(t10_scores)).reshape((len(pt_labels),-1)).T, \n",
    "             columns=pt_labels)\n",
    "t10_results ## number of correct predictions of top 10 FCC values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference\n",
    "dif_list = []\n",
    "for i in t10_sets: \n",
    "    dif_list.append(i.difference(gt_t10_set))\n",
    "\n",
    "for i in dif_list: \n",
    "    print(rank_df['gt'].loc[lambda x: x.isin(i)].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gayles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
